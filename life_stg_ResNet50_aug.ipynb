{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6481902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "import glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pydot\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2M\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5250abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = r\"D:/experiments/Datasets/ip102_v1.1-002/ip102_v1.1/prepared_data/train_stg/\"\n",
    "valid_data_dir = r\"D:/experiments/Datasets/ip102_v1.1-002/ip102_v1.1/prepared_data/val_stg/\"\n",
    "test_data_dir = r\"D:/experiments/Datasets/ip102_v1.1-002/ip102_v1.1/prepared_data/test_stg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c09b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "        'Adult',\n",
    "        'Larva',\n",
    "        'Pupa',\n",
    "        'Egg'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63597f0d",
   "metadata": {},
   "source": [
    "ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56114678",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85802c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without data augmentation\n",
    "# datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4deff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38400 images belonging to 4 classes.\n",
      "Found 6352 images belonging to 4 classes.\n",
      "Found 20047 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batchs_Res = datagen.flow_from_directory(directory=train_data_dir, target_size=(224,224), classes=classes,class_mode='categorical', batch_size=64)\n",
    "\n",
    "valid_batchs_Res = datagen.flow_from_directory(directory=valid_data_dir, target_size=(224,224), classes=classes,class_mode='categorical', batch_size=64)\n",
    "\n",
    "test_batchs_Res = datagen.flow_from_directory(directory=test_data_dir, target_size=(224,224), classes=classes,class_mode='categorical', batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20dfc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_Res = ResNet50(include_top = False, weights = 'imagenet',input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model_Res.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cab34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model_Res.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(train_batchs_Res.num_classes, activation='softmax')(x)\n",
    "\n",
    "modelRes = Model(inputs=base_model_Res.input, outputs=predictions)\n",
    "modelRes.compile(optimizer = Adam(learning_rate=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5ddb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(\"SavedModels/ResNet50/ResNet50_stg_Adam.h5\", verbose=1, save_best_model=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-6),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44f39e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.9294\n",
      "Epoch 1: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "600/600 [==============================] - 207s 341ms/step - loss: 0.1991 - accuracy: 0.9294 - val_loss: 0.5413 - val_accuracy: 0.8378 - lr: 1.0000e-04\n",
      "Epoch 2/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9583\n",
      "Epoch 2: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "600/600 [==============================] - 204s 339ms/step - loss: 0.1217 - accuracy: 0.9583 - val_loss: 0.1785 - val_accuracy: 0.9459 - lr: 1.0000e-04\n",
      "Epoch 3/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9646\n",
      "Epoch 3: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "600/600 [==============================] - 204s 340ms/step - loss: 0.1007 - accuracy: 0.9646 - val_loss: 0.1842 - val_accuracy: 0.9426 - lr: 1.0000e-04\n",
      "Epoch 4/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9707\n",
      "Epoch 4: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "600/600 [==============================] - 205s 341ms/step - loss: 0.0839 - accuracy: 0.9707 - val_loss: 0.1909 - val_accuracy: 0.9503 - lr: 1.0000e-04\n",
      "Epoch 5/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9738\n",
      "Epoch 5: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "600/600 [==============================] - 204s 340ms/step - loss: 0.0753 - accuracy: 0.9738 - val_loss: 0.2037 - val_accuracy: 0.9471 - lr: 1.0000e-04\n",
      "Epoch 6/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9846\n",
      "Epoch 6: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "600/600 [==============================] - 204s 340ms/step - loss: 0.0447 - accuracy: 0.9846 - val_loss: 0.1591 - val_accuracy: 0.9616 - lr: 1.0000e-05\n",
      "Epoch 7/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9892\n",
      "Epoch 7: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "600/600 [==============================] - 208s 346ms/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.1647 - val_accuracy: 0.9635 - lr: 1.0000e-05\n",
      "Epoch 8/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9906\n",
      "Epoch 8: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "600/600 [==============================] - 207s 344ms/step - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.1754 - val_accuracy: 0.9648 - lr: 1.0000e-05\n",
      "Epoch 9/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9920\n",
      "Epoch 9: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "600/600 [==============================] - 237s 395ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.1740 - val_accuracy: 0.9640 - lr: 1.0000e-05\n",
      "Epoch 10/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9934\n",
      "Epoch 10: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "600/600 [==============================] - 323s 537ms/step - loss: 0.0180 - accuracy: 0.9934 - val_loss: 0.1799 - val_accuracy: 0.9639 - lr: 1.0000e-06\n",
      "Epoch 11/500\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9941\n",
      "Epoch 11: saving model to SavedModels/ResNet50\\ResNet50_stg_Adam.h5\n",
      "600/600 [==============================] - 205s 341ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.1822 - val_accuracy: 0.9658 - lr: 1.0000e-06\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_Res = modelRes.fit(x = train_batchs_Res, \n",
    "            steps_per_epoch=train_batchs_Res.samples // 64,\n",
    "            validation_data = valid_batchs_Res,\n",
    "            validation_steps=valid_batchs_Res.samples // 64,\n",
    "            epochs = 500, verbose = 1,\n",
    "            callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49906e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Res_model = tf.keras.models.load_model('SavedModels/ResNet50/ResNet50_stg_Adam.h5')\n",
    "\n",
    "Res_predictions = Res_model.predict(x=test_batchs_Res, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ffd7fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.963087\n",
      "Precision: 0.962437\n",
      "Recall: 0.963087\n",
      "F1 score: 0.962485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Adult       0.98      0.98      0.98     16252\n",
      "       Larva       0.90      0.93      0.91      3344\n",
      "        Pupa       0.81      0.63      0.71       356\n",
      "         Egg       0.67      0.51      0.57        95\n",
      "\n",
      "    accuracy                           0.96     20047\n",
      "   macro avg       0.84      0.76      0.79     20047\n",
      "weighted avg       0.96      0.96      0.96     20047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_Res = np.argmax(Res_predictions, axis=1)\n",
    "y_true_Res = test_batchs_Res.classes\n",
    "\n",
    "accuracy = accuracy_score(y_true_Res, y_pred_Res)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "precision = precision_score(y_true_Res, y_pred_Res, average='weighted', zero_division=0)\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "recall = recall_score(y_true_Res, y_pred_Res, average='weighted', zero_division=0)\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "f1 = f1_score(y_true_Res, y_pred_Res, average='weighted', zero_division=0)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "print(classification_report(y_true_Res, y_pred_Res, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "016420dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the filename including last folder\n",
    "image_names = [os.path.basename(filename) for filename in test_batchs_Res.filenames]\n",
    "\n",
    "\n",
    "# Get the image names from the ImageDataGenerator\n",
    "image_names = test_batchs_Res.filenames\n",
    "\n",
    "df = pd.DataFrame({'Image Name': image_names, 'Predicted': y_pred_Res, 'Ground Truth': y_true_Res})\n",
    "df.to_csv('ResNet50_stg_Adam.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matRes = confusion_matrix(y_true_Res,y_pred_Res)\n",
    "plot_confusion_matrix(matRes, figsize=(4,4), class_names=classes, show_normed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
